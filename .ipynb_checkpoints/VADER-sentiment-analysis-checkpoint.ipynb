{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.tag import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('programming_for_everybody.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 most common reviews\n",
    "\n",
    "df['review'].value_counts().head(10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicates seem to be from different learners\n",
    "\n",
    "df[(df.review == 'good')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most reviews have a good rating - the dataset is not balanced, there should be more positive than negative reviews\n",
    "\n",
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most people have given a rating of 5\n",
    "\n",
    "plt.figure(figsize =(10, 7)) \n",
    "plt.pie([8925, 1033, 163], labels = ['5', '4', '1 - 3'], autopct='%1.1f%%');\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values\n",
    "\n",
    "df.isnull().sum() * 100 / df.shape[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in 'review'\n",
    "\n",
    "len(df[df['review'].isna()==True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values\n",
    "\n",
    "df.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in 'review'\n",
    "\n",
    "len(df[df['review'].isna()==True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column 'length'\n",
    "\n",
    "df['length'] = df['review'].astype(str).apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The average length of a review is 77 words - reviews are in general short\n",
    "\n",
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The longest reviews have a rating of 1-2. Shortest reviews have a rating of 3. \n",
    "\n",
    "px.box(df, x = \"rating\", y = \"length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label reviews as positive, negative and neutral depending on their rating\n",
    "\n",
    "label = []\n",
    "\n",
    "for row in df['rating']:\n",
    "    if row == 1 or row == 2:\n",
    "        label.append('neg')\n",
    "    elif row == 3:\n",
    "        label.append('neu')\n",
    "    else:\n",
    "        label.append('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 98 % of the reviews are positive according to the rating\n",
    "\n",
    "plt.figure(figsize =(10, 7)) \n",
    "plt.pie([9956, 99, 64], labels = ['Positive', 'Neutral', 'Negative'], autopct='%1.1f%%');\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code borrowed from: https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vader = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vader sentiment calculator \n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply vader to the reviews\n",
    "\n",
    "df_vader['scores'] = df_vader['review'].apply(lambda review: sid.polarity_scores(review))\n",
    "\n",
    "df_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the compound score from each review\n",
    "\n",
    "df_vader['compound']  = df_vader['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "df_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We once again label reviews as positive, negative and neutral depending on their compound score\n",
    "\n",
    "sentiment = []\n",
    "\n",
    "for row in df_vader['compound']:\n",
    "    if row < 0:\n",
    "        sentiment.append('neg')\n",
    "    elif row > 0:\n",
    "        sentiment.append('pos')\n",
    "    else:\n",
    "        sentiment.append('neu')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vader['sentiment'] = sentiment\n",
    "\n",
    "df_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER could predict the sentiment of the reviews with almost 88% accuracy (using the rating as the accuracy measure for evaluation)\n",
    "\n",
    "print( 'The accuracy of the sentiment prediction is ', accuracy_score(label, sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on sentence-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\"\n",
    "df_sen['review'] = df_sen.loc[:10120, \"review\"].apply(lambda x: re.split(rule, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen = df_sen.explode(\"review\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen['review_index'] = df_sen.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the columns\n",
    "\n",
    "df_sen = df_sen[['review_index', 'date', 'review', 'rating', 'status', 'length', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen = df_sen.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update length column\n",
    "\n",
    "df_sen['length'] = df_sen['review'].astype(str).apply(len)\n",
    "df_sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply vader to the reviews\n",
    "\n",
    "df_sen['scores'] = df_sen['review'].apply(lambda review: sid.polarity_scores(review))\n",
    "\n",
    "df_sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the compound score from each review\n",
    "\n",
    "df_sen['compound']  = df_sen['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "df_sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_1 = []\n",
    "\n",
    "for row in df_sen['compound']:\n",
    "    if row < 0:\n",
    "        sentiment_1.append('neg')\n",
    "    elif row > 0:\n",
    "        sentiment_1.append('pos')\n",
    "    else:\n",
    "        sentiment_1.append('neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen['sentiment'] = sentiment_1\n",
    "\n",
    "df_sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling on sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with the original sentences\n",
    "\n",
    "df_sen['original'] = df_sen['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert to lowercase\n",
    "\n",
    "df_sen['review'] =  df_sen['review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df_sen['review'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations\n",
    "\n",
    "df_sen['review'] = df_sen['review'].str.replace('[^\\w\\s]','')\n",
    "df_sen['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df_sen['review'] = df_sen['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df_sen['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "df_sen['review'] = df_sen['review'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df_sen['review'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add speech tags\n",
    "\n",
    "df_sen['review'] = df_sen['review'].apply(nltk.tag.pos_tag)\n",
    "df_sen['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert parts of speech tags to wordnet’s format\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the tagged data\n",
    "\n",
    "df_sen['review'] = df_sen['review'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "df_sen['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply to data \n",
    "\n",
    "df_sen['review'] = df_sen['review'].apply(lambda x: [lemmatizer.lemmatize(word, tag) for word, tag in x])\n",
    "df_sen['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Topic-Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words on the Data set\n",
    "# Create a dictionary from 'df_sen['review']' containing the number of times a word appears in the training set\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(df_sen['review'])\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim filter extremes\n",
    "\n",
    "# Filter out tokens that appear in:\n",
    "# Less than 30 documents, more than 0.5 documents, and keep only 100000 most frquent tokens\n",
    "\n",
    "dictionary.filter_extremes(no_below = 50, no_above = 0.5, keep_n = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim doc2bow\n",
    "# Create a dictionary reporting how many words and how many times those words appear\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in df_sen['review']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)      # Create a TF-IDF model\n",
    "corpus_tfidf = tfidf[bow_corpus]           # Apply transformation to the entire corpus and call it ‘corpus_tfidf’\n",
    "\n",
    "for doc in corpus_tfidf:       # Preview for the first document\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run parallelized LDA using Tf-IDF\n",
    "\n",
    "%timeit\n",
    "lda_model = gensim.models.LdaMulticore(corpus_tfidf, num_topics = 6, id2word = dictionary, passes = 10, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the words occurring in that topic and its relative weight\n",
    "\n",
    "for id, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {}\\nWord: {}\\n'.format(id, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column with the topic\n",
    "\n",
    "df_sen['topic'] = ''\n",
    "\n",
    "df_sen['topic'] = [max(p, key = lambda item: item[1]) for p in lda_model[corpus_tfidf]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two separate columns for the topic ID and topic score\n",
    "\n",
    "df_sen[['topic_id', 'topic_score']] = df_sen['topic'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
